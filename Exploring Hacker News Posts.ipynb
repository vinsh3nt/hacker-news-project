{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analyzing Hacker News Posts\n",
    "\n",
    "Hacker News is a site similar to Reddit where users can submit stories and vote and comment on them. Hacker News is popular in tech and startup circles and posts that make it to the top can get hundreds of thousands of visitors.\n",
    "\n",
    "The dataset we will be analyzing can be found [here](https://www.kaggle.com/hacker-news/hacker-news-posts), it has been reduced from 300,000 rows to 20,000 by eliminating any submissions without any comments and then randomly sampling from the remaining submissions.\n",
    "\n",
    "Below are the descriptions of the columns:\n",
    "* **id**: Identifier from Hacker News for the post\n",
    "* **title**: The title of the post\n",
    "* **url**: The URL that the posts links to, if the post has a URL\n",
    "* **num_points**: The number of points the post has, calculated as the number of upvotes minus the number of downvotes\n",
    "* **num_comments**: The number of comments made on the post\n",
    "* **author**: The username of the person who submitted the post\n",
    "* **created_at**: The date and time at which the post was submitted\n",
    "\n",
    "For this project we are interested in posts with titles that begin with either \"Ask HN\" or \"Show HN\".\n",
    "\n",
    "Ask HN posts are used to ask the community specific questions while Show HN posts are to show a project, product, or just something interesting to the community.\n",
    "\n",
    "We'll compare these two types of posts to determine:\n",
    "* Do Ask HN or Show HN posts receive more comments on average?\n",
    "* Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "##  Reading the Data\n",
    "Lets read in the data and view the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'],\n",
       " ['12224879',\n",
       "  'Interactive Dynamic Video',\n",
       "  'http://www.interactivedynamicvideo.com/',\n",
       "  '386',\n",
       "  '52',\n",
       "  'ne0phyte',\n",
       "  '8/4/2016 11:52'],\n",
       " ['10975351',\n",
       "  'How to Use Open Source and Shut the Fuck Up at the Same Time',\n",
       "  'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/',\n",
       "  '39',\n",
       "  '10',\n",
       "  'josep2',\n",
       "  '1/26/2016 19:30'],\n",
       " ['11964716',\n",
       "  \"Florida DJs May Face Felony for April Fools' Water Joke\",\n",
       "  'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/',\n",
       "  '2',\n",
       "  '1',\n",
       "  'vezycash',\n",
       "  '6/23/2016 22:20'],\n",
       " ['11919867',\n",
       "  'Technology ventures: From Idea to Enterprise',\n",
       "  'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
       "  '3',\n",
       "  '1',\n",
       "  'hswarna',\n",
       "  '6/17/2016 0:01']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "\n",
    "hn[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['12224879',\n",
       "  'Interactive Dynamic Video',\n",
       "  'http://www.interactivedynamicvideo.com/',\n",
       "  '386',\n",
       "  '52',\n",
       "  'ne0phyte',\n",
       "  '8/4/2016 11:52'],\n",
       " ['10975351',\n",
       "  'How to Use Open Source and Shut the Fuck Up at the Same Time',\n",
       "  'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/',\n",
       "  '39',\n",
       "  '10',\n",
       "  'josep2',\n",
       "  '1/26/2016 19:30'],\n",
       " ['11964716',\n",
       "  \"Florida DJs May Face Felony for April Fools' Water Joke\",\n",
       "  'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/',\n",
       "  '2',\n",
       "  '1',\n",
       "  'vezycash',\n",
       "  '6/23/2016 22:20'],\n",
       " ['11919867',\n",
       "  'Technology ventures: From Idea to Enterprise',\n",
       "  'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
       "  '3',\n",
       "  '1',\n",
       "  'hswarna',\n",
       "  '6/17/2016 0:01'],\n",
       " ['10301696',\n",
       "  'Note by Note: The Making of Steinway L1037 (2007)',\n",
       "  'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0',\n",
       "  '8',\n",
       "  '2',\n",
       "  'walterbell',\n",
       "  '9/30/2015 4:12']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign header row to a variable and remove from the original dataset\n",
    "\n",
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "print(headers)\n",
    "print()\n",
    "hn[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering the Data\n",
    "\n",
    "Since we are only concerned with post titles beginning with Ask HN or Show HN we will create new 2D lists that contain just the data for those titles. To do this we will be using the string method startswith."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith(\"ask hn\"):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith(\"show hn\"):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Average Comments by Post Type\n",
    "\n",
    "Now that we have separated out the types of posts we can determine whether ask posts or show posts receive more comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3497.5714285714284\n",
      "1712.5714285714287\n"
     ]
    }
   ],
   "source": [
    "# Find total number of comments in ask posts\n",
    "total_ask_comments = 0\n",
    "for post in ask_posts:\n",
    "    num_comments = post[4]\n",
    "    num_comments = int(num_comments)\n",
    "    total_ask_comments += num_comments\n",
    "\n",
    "# Compute and show the avg\n",
    "avg_ask_comments = total_ask_comments / len(hn[4])\n",
    "print(avg_ask_comments)\n",
    "\n",
    "# Find total number of comments in show posts\n",
    "total_show_comments = 0\n",
    "for post in show_posts:\n",
    "    num_comments = post[4]\n",
    "    num_comments = int(num_comments)\n",
    "    total_show_comments += num_comments\n",
    "    \n",
    "# Compute and show the avg\n",
    "avg_show_comments = total_show_comments / len(hn[4])\n",
    "print(avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears in our sample data that on average, ask posts see more commenter engagement than show posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Amount of Ask Posts and Comments by Hour Created\n",
    "\n",
    "So we have determined through our basic analysis that Ask posts receive more comments on average. Since these kinds of posts are more likely to receive comments we will focus our analysis on them. Let's determine whether Ask posts created at a certain ***time*** are more likely to attract commenters.\n",
    "\n",
    "To do so we will use the following steps:\n",
    "1. Calculate the amount of ask posts created in each hour of the day along with comments recieved.\n",
    "2. Calculate the average number of comments ask posts recieve by hour created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00': 447,\n",
       " '01': 683,\n",
       " '02': 1381,\n",
       " '03': 421,\n",
       " '04': 337,\n",
       " '05': 464,\n",
       " '06': 397,\n",
       " '07': 267,\n",
       " '08': 492,\n",
       " '09': 251,\n",
       " '10': 793,\n",
       " '11': 641,\n",
       " '12': 687,\n",
       " '13': 1253,\n",
       " '14': 1416,\n",
       " '15': 4477,\n",
       " '16': 1814,\n",
       " '17': 1146,\n",
       " '18': 1439,\n",
       " '19': 1188,\n",
       " '20': 1722,\n",
       " '21': 1745,\n",
       " '22': 479,\n",
       " '23': 543}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "# Create an empty list to store the time created and the number of comments\n",
    "result_list = []\n",
    "\n",
    "# Iterate over ask_posts and append the time and comments to result_list\n",
    "for row in ask_posts:\n",
    "    timecreated = row[6]\n",
    "    numcomments = int(row[4])\n",
    "    result_list.append([timecreated, numcomments])\n",
    "\n",
    "# Create two  empty dictionaries to act as frequency tables\n",
    "# One tracks the number of posts made by hour\n",
    "# One tracks the number of comments made by hour\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "# Specify the date format in our data\n",
    "date_format = \"%m/%d/%Y %H:%M\"\n",
    "\n",
    "# Iterate over the result list, extract the hour from the date\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    comment = row[1]\n",
    "    time = dt.datetime.strptime(date, date_format).strftime(\"%H\")  # Select just the hour\n",
    "    # If the hour is a key, increment the values\n",
    "    if time in counts_by_hour:\n",
    "        comments_by_hour[time] += comment\n",
    "        counts_by_hour[time] += 1\n",
    "    # If the hour is not a key, create a key and set to 1, create comment key and set equal to comment\n",
    "    else:\n",
    "        comments_by_hour[time] = comment\n",
    "        counts_by_hour[time] = 1\n",
    "\n",
    "comments_by_hour\n",
    "counts_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the two dictionaries:\n",
    "* counts_by_hour: contains the number of ask posts created each hour of the day\n",
    "* comments_by_hour: containts the corresponding number of comments received by hour\n",
    "\n",
    "We can calculate the average number of comments for posts created during each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['16', 16.796296296296298],\n",
       " ['18', 13.20183486238532],\n",
       " ['13', 14.741176470588234],\n",
       " ['08', 10.25],\n",
       " ['07', 7.852941176470588],\n",
       " ['21', 16.009174311926607],\n",
       " ['09', 5.5777777777777775],\n",
       " ['05', 10.08695652173913],\n",
       " ['04', 7.170212765957447],\n",
       " ['02', 23.810344827586206],\n",
       " ['03', 7.796296296296297],\n",
       " ['00', 8.127272727272727],\n",
       " ['23', 7.985294117647059],\n",
       " ['01', 11.383333333333333],\n",
       " ['20', 21.525],\n",
       " ['11', 11.051724137931034],\n",
       " ['19', 10.8],\n",
       " ['10', 13.440677966101696],\n",
       " ['15', 38.5948275862069],\n",
       " ['06', 9.022727272727273],\n",
       " ['22', 6.746478873239437],\n",
       " ['17', 11.46],\n",
       " ['12', 9.41095890410959],\n",
       " ['14', 13.233644859813085]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty list to store the results\n",
    "\n",
    "avg_by_hour = []\n",
    "\n",
    "for hr in comments_by_hour:\n",
    "    avg_by_hour.append([hr, comments_by_hour[hr]/counts_by_hour[hr]])\n",
    "    \n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting and Displaying the Values\n",
    "\n",
    "We now have the results we were looking for but the readability of the list leaves something to be desired. Let's try now to present our results in a format that is easier to read and understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16.796296296296298, '16'], [13.20183486238532, '18'], [14.741176470588234, '13'], [10.25, '08'], [7.852941176470588, '07'], [16.009174311926607, '21'], [5.5777777777777775, '09'], [10.08695652173913, '05'], [7.170212765957447, '04'], [23.810344827586206, '02'], [7.796296296296297, '03'], [8.127272727272727, '00'], [7.985294117647059, '23'], [11.383333333333333, '01'], [21.525, '20'], [11.051724137931034, '11'], [10.8, '19'], [13.440677966101696, '10'], [38.5948275862069, '15'], [9.022727272727273, '06'], [6.746478873239437, '22'], [11.46, '17'], [9.41095890410959, '12'], [13.233644859813085, '14']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[38.5948275862069, '15'],\n",
       " [23.810344827586206, '02'],\n",
       " [21.525, '20'],\n",
       " [16.796296296296298, '16'],\n",
       " [16.009174311926607, '21'],\n",
       " [14.741176470588234, '13'],\n",
       " [13.440677966101696, '10'],\n",
       " [13.233644859813085, '14'],\n",
       " [13.20183486238532, '18'],\n",
       " [11.46, '17'],\n",
       " [11.383333333333333, '01'],\n",
       " [11.051724137931034, '11'],\n",
       " [10.8, '19'],\n",
       " [10.25, '08'],\n",
       " [10.08695652173913, '05'],\n",
       " [9.41095890410959, '12'],\n",
       " [9.022727272727273, '06'],\n",
       " [8.127272727272727, '00'],\n",
       " [7.985294117647059, '23'],\n",
       " [7.852941176470588, '07'],\n",
       " [7.796296296296297, '03'],\n",
       " [7.170212765957447, '04'],\n",
       " [6.746478873239437, '22'],\n",
       " [5.5777777777777775, '09']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "    \n",
    "print(swap_avg_by_hour)\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "sorted_swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for 'Ask HN' Comments\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "# Sort the values and print out the top 5 hours with the most comments on avg\n",
    "\n",
    "print(\"Top 5 Hours for 'Ask HN' Comments\")\n",
    "for avg, hr in sorted_swap[:5]:\n",
    "    print(\n",
    "        \"{}: {:.2f} average comments per post\".format(\n",
    "            dt.datetime.strptime(hr, \"%H\").strftime(\"%H:%M\"),avg\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "By working with datetimes and strings we were able to determine the hours that see the most number of posts, which hours see the highest number of commenters, and whichs hours see the highest number of comments on average."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
